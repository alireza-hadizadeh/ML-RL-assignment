

# 📝 گزارش پروژه: پیاده‌سازی درخت تصمیم به سبک C4.5 با معیار Gain Ratio

---

## 1. هدف پروژه

هدف این پروژه، **ساخت یک درخت تصمیم‌گیری با استفاده از الگوریتم C4.5** برای پیش‌بینی اینکه آیا در یک روز خاص و با شرایط آب‌وهوایی داده‌شده، تنیس بازی خواهیم کرد یا نه است.

برای این منظور:

* از دیتاست معروف **PlayTennis** استفاده شده
* الگوریتم **C4.5** به صورت بازگشتی و دستی پیاده‌سازی شده است
* از **معیار Gain Ratio** برای انتخاب بهترین ویژگی در هر گره استفاده شده
* در نهایت، مدل با **معیارهای ارزیابی مختلف** بررسی شده است

---

## 2. معرفی داده‌ها

### 📋 دیتاست: PlayTennis

این دیتاست شامل 14 نمونه (روز) است و 5 ستون دارد:

| ویژگی (Feature) | نوع داده   | توضیح                                          |
| --------------- | ---------- | ---------------------------------------------- |
| Outlook         | متنی       | وضعیت هوا: Sunny, Rain, Overcast               |
| Temperature     | متنی       | دما: Hot, Mild, Cool                           |
| Humidity        | متنی       | رطوبت: High, Normal                            |
| Wind            | متنی       | باد: Weak, Strong                              |
| PlayTennis      | متنی (هدف) | خروجی نهایی: Yes یا No (آیا تنیس بازی می‌شود؟) |

---

## 3. پیش‌پردازش داده‌ها

* **تبدیل برچسب (PlayTennis)** به مقادیر عددی:

  * Yes → 1
  * No → 0
* سایر ویژگی‌ها بدون تغییر باقی مانده‌اند چون الگوریتم C4.5 از ویژگی‌های **گسسته/متنی** پشتیبانی می‌کند.
* نیازی به نرمال‌سازی، نر کردن، یا Imputation نبوده زیرا داده‌ها کامل هستند.

---

## 4. پیاده‌سازی الگوریتم C4.5

### 🔧 مراحل کلیدی الگوریتم:

1. در هر گره، اگر خروجی‌ها فقط شامل یک کلاس باشند (فقط Yes یا فقط No)، آن گره به عنوان **برگ نهایی** در نظر گرفته می‌شود.
2. در غیر این صورت، برای همه ویژگی‌های باقی‌مانده:

   * **Gain Ratio** آن‌ها محاسبه می‌شود.
   * ویژگی‌ای که **بیشترین Gain Ratio** را دارد به عنوان **بهترین ویژگی برای تقسیم** انتخاب می‌شود.
3. سپس داده‌ها بر اساس مقدارهای آن ویژگی تقسیم شده و این مراحل به صورت **بازگشتی** تکرار می‌شود تا کل درخت ساخته شود.

### 📌 معیار Gain Ratio:

$$
Gain\ Ratio(A) = \frac{Information\ Gain(A)}{SplitInfo(A)}
$$

* Information Gain میزان کاهش آنتروپی را نشان می‌دهد.
* SplitInfo پراکندگی ویژگی را در نظر می‌گیرد.
* نتیجه: **ویژگی‌هایی که تقسیمات زیادی ایجاد می‌کنند بدون معنا، جریمه می‌شوند.**

---

## 5. پیش‌بینی

پس از ساخت درخت، پیش‌بینی خروجی هر ردیف از داده‌ها با **پیمایش از ریشه تا برگ‌ها** انجام شد. اگر برای مقدار یک ویژگی فرزندی در درخت وجود نداشت، پیش‌فرض خروجی "Yes" در نظر گرفته شد (برای جلوگیری از خطا در داده‌های نادیده).

---

## 6. ارزیابی مدل

پیش‌بینی روی همان داده آموزشی انجام شده و معیارهای زیر محاسبه شد:

### ✅ Confusion Matrix:

|            | Predicted No | Predicted Yes |
| ---------- | ------------ | ------------- |
| Actual No  | TN = 5       | FP = 0        |
| Actual Yes | FN = 0       | TP = 9        |

### 📊 معیارهای ارزیابی:

| معیار                       | مقدار |
| --------------------------- | ----- |
| Accuracy (دقت کلی)          | 1.00  |
| Precision (دقت در Yes)      | 1.00  |
| Recall (Sensitivity)        | 1.00  |
| Specificity (تشخیص درست No) | 1.00  |
| F1 Score                    | 1.00  |
| SPB (شاخص Youden)           | 1.00  |

> توجه: چون پیش‌بینی روی داده آموزش انجام شده، دقت کامل به دست آمده است. در عمل باید با داده تست جداگانه مدل را ارزیابی کرد.

---

## 7. نتیجه‌گیری

* الگوریتم C4.5 با معیار Gain Ratio با موفقیت پیاده‌سازی شد و ساختار درخت تصمیم کاملاً بر اساس انتخاب ویژگی‌های مؤثر پیش رفت.
* دقت بالا نشان می‌دهد مدل به‌خوبی با داده آموزش سازگار شده است.
* برای جلوگیری از **بیش‌برازش (Overfitting)**، توصیه می‌شود مدل را روی داده‌های تست نیز بررسی کرد.
