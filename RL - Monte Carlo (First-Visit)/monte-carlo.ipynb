{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f650b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 0), 'down'): -0.23\n",
      "((0, 0), 'left'): 0.88\n",
      "((0, 0), 'right'): 0.89\n",
      "((0, 0), 'up'): 0.44\n",
      "((0, 1), 'down'): -0.10\n",
      "((0, 1), 'left'): 0.45\n",
      "((0, 1), 'right'): 0.95\n",
      "((0, 1), 'up'): 0.89\n",
      "((0, 2), 'down'): 0.90\n",
      "((0, 2), 'left'): 0.91\n",
      "((0, 2), 'right'): 0.98\n",
      "((0, 2), 'up'): 0.95\n",
      "((0, 3), 'down'): 1.00\n",
      "((0, 3), 'left'): 0.95\n",
      "((0, 3), 'right'): 0.98\n",
      "((0, 3), 'up'): 0.98\n",
      "((1, 0), 'down'): -4.37\n",
      "((1, 0), 'left'): -4.10\n",
      "((1, 0), 'right'): -0.86\n",
      "((1, 0), 'up'): 0.53\n",
      "((1, 2), 'down'): 0.96\n",
      "((1, 2), 'left'): -0.62\n",
      "((1, 2), 'right'): 1.00\n",
      "((1, 2), 'up'): 0.90\n",
      "\n",
      "✅ Monte Carlo Success rate: 100.00% in 100 test episodes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------- تنظیمات محیط ----------\n",
    "GRID = [\n",
    "    ['S', '-', '-', '-'],\n",
    "    ['-', '#', '-', 'G']\n",
    "]\n",
    "ACTIONS = ['up', 'down', 'left', 'right']\n",
    "GAMMA = 0.99\n",
    "EPSILON = 0.1\n",
    "\n",
    "def get_start_state():\n",
    "    for i, row in enumerate(GRID):\n",
    "        for j, cell in enumerate(row):\n",
    "            if cell == 'S':\n",
    "                return (i, j)\n",
    "\n",
    "def is_terminal(state):\n",
    "    i, j = state\n",
    "    return GRID[i][j] == 'G'\n",
    "\n",
    "def step(state, action):\n",
    "    i, j = state\n",
    "    if action == 'up':\n",
    "        i = max(0, i - 1)\n",
    "    elif action == 'down':\n",
    "        i = min(len(GRID) - 1, i + 1)\n",
    "    elif action == 'left':\n",
    "        j = max(0, j - 1)\n",
    "    elif action == 'right':\n",
    "        j = min(len(GRID[0]) - 1, j + 1)\n",
    "\n",
    "    if GRID[i][j] == '#':\n",
    "        return state, -1, False\n",
    "    elif GRID[i][j] == 'G':\n",
    "        return (i, j), +1, True\n",
    "    else:\n",
    "        return (i, j), -0.01, False\n",
    "\n",
    "def epsilon_greedy(Q, state):\n",
    "    if random.random() < EPSILON:\n",
    "        return random.choice(ACTIONS)\n",
    "    values = [Q[(state, a)] for a in ACTIONS]\n",
    "    return ACTIONS[np.argmax(values)]\n",
    "\n",
    "# ---------- الگوریتم مونت‌کارلو ----------\n",
    "def monte_carlo_control(num_episodes=1000):\n",
    "    Q = defaultdict(float)\n",
    "    returns = defaultdict(list)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = get_start_state()\n",
    "        episode_data = []\n",
    "        \n",
    "        # Generate episode\n",
    "        while not is_terminal(state):\n",
    "            action = epsilon_greedy(Q, state)\n",
    "            next_state, reward, done = step(state, action)\n",
    "            episode_data.append((state, action, reward))\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Calculate returns and update Q\n",
    "        G = 0\n",
    "        visited = set()\n",
    "        for t in reversed(range(len(episode_data))):\n",
    "            s, a, r = episode_data[t]\n",
    "            G = GAMMA * G + r\n",
    "            if (s, a) not in visited:\n",
    "                visited.add((s, a))\n",
    "                returns[(s, a)].append(G)\n",
    "                Q[(s, a)] = np.mean(returns[(s, a)])\n",
    "\n",
    "    return Q\n",
    "\n",
    "# ---------- ارزیابی ----------\n",
    "def evaluate_policy(Q, episodes=100):\n",
    "    success = 0\n",
    "    for _ in range(episodes):\n",
    "        state = get_start_state()\n",
    "        while not is_terminal(state):\n",
    "            values = [Q[(state, a)] for a in ACTIONS]\n",
    "            best_action = ACTIONS[np.argmax(values)]\n",
    "            next_state, reward, done = step(state, best_action)\n",
    "            state = next_state\n",
    "            if done and reward > 0:\n",
    "                success += 1\n",
    "    print(f\"\\n✅ Monte Carlo Success rate: {success / episodes * 100:.2f}% in {episodes} test episodes.\")\n",
    "\n",
    "# ---------- اجرا ----------\n",
    "Q_mc = monte_carlo_control()\n",
    "for key in sorted(Q_mc.keys()):\n",
    "    print(f\"{key}: {Q_mc[key]:.2f}\")\n",
    "\n",
    "evaluate_policy(Q_mc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
